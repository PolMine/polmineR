#' @include S4classes.R
NULL

#' Get markdown-formatted full text of a partition.
#' 
#' The method is the worker behind the \code{read}-method, which will be called
#' usually to reconstruct the full text of a \code{partition} and read it. The
#' \code{as.markdown}-method can be customized for different classes inheriting
#' from the \code{partition}-class.
#' 
#' @param .Object The object to be converted, a \code{partition}, or a class
#'   inheriting from \code{partition}, such as \code{plpr_partition}.
#' @param meta The metainformation (s-attributes) to be displayed.
#' @param cpos A \code{logical} value, whether to add cpos as ids in span elements.
#' @param interjections A \code{logical} value, whether to format interjections.
#' @param cutoff The maximum number of tokens to reconstruct, to avoid that full text is
#' excessively long.
#' @param template A template for formating output.
#' @param verbose A \code{logical} value, whether to output messages.
#' @param ... further arguments
#' @rdname as.markdown
#' @exportMethod as.markdown
#' @examples
#' use("polmineR")
#' P <- partition("REUTERS", places = "argentina")
#' as.markdown(P)
#' as.markdown(P, meta = c("id", "places"))
#' if (interactive()) read(P, meta = c("id", "places"))
setGeneric("as.markdown", function(.Object, ...) standardGeneric("as.markdown"))

# vectorized sprintf is considerably faster than shiny::span,
# an alternative that could be considered
.tagTokens <- function(tokens){
  if (is.null(names(tokens))) {
    return( sprintf('<span token="%s" class="fulltext">%s</span>', tokens, tokens) )
  } else {
    return( sprintf('<span id="%s" token="%s" class="fulltext">%s</span>', names(tokens), tokens, tokens) )
  }
}


.as.markdown <- function(.Object, corpus, meta = NULL, cpos = FALSE, cutoff = NULL, ...){
  corpusEncoding <- cl_charset_name(corpus)
  
  if (is.null(get_template(corpus))){
    warning(
      sprintf(
        "No template available for corpus '%s', it will not be possible to format fulltext output.",
        corpus
      )
    )
  }
  
  # generate metainformation
  documentStruc <- cl_cpos2struc(
    corpus = corpus, registry = corpus_registry_dir(corpus),
    s_attribute = get_template(corpus)[["document"]][["sAttribute"]],
    cpos = .Object[1]
  )

  metaInformation <- sapply(
    meta,
    function(x) {
      retval <- cl_struc2str(
        corpus = corpus, registry = corpus_registry_dir(corpus),
        s_attribute = x, struc = documentStruc
      )
      Encoding(retval) <- corpusEncoding
      as.nativeEnc(retval, from = corpusEncoding)
    })
  names(metaInformation) <- meta
  
  metaInformation <- paste(metaInformation, collapse = ", ") # string will be converted to UTF-8
  metaInformation <- paste(
    get_template(corpus)[["document"]][["format"]][1],
    metaInformation,
    get_template(corpus)[["document"]][["format"]][2],
    sep = ""
    )
  
  cposSeries <- .Object[1]:.Object[2]
  pStrucs <- cl_cpos2struc(
    corpus = corpus, registry = corpus_registry_dir(corpus),
    s_attribute = get_template(corpus)[["paragraphs"]][["sAttribute"]], cpos = cposSeries
  )
  chunks <- split(cposSeries, pStrucs)
  pTypes <- cl_struc2str(
    corpus = corpus, registry = corpus_registry_dir(corpus),
    s_attribute = get_template(corpus)[["paragraphs"]][["sAttribute"]],
    struc = as.numeric(names(chunks))
  )
  bodyList <- Map(
    function(pType, chunk){
      tokens <- get_token_stream(
        chunk, corpus = corpus, p_attribute = "word",
        encoding = corpusEncoding, cpos = cpos, cutoff = cutoff
      )
      tokens <- .tagTokens(tokens)
      paste(
        get_template(corpus)[["paragraphs"]][["format"]][[pType]][1],
        paste(tokens, collapse = " "),
        get_template(corpus)[["paragraphs"]][["format"]][[pType]][2],
        sep = ""
      )
    },
    pTypes, chunks
  )
  article <- c(metaInformation, unlist(bodyList))
  markdown <- paste(article, collapse = "\n\n")
  markdown <- gsub("(.)\\s([,.:!?])", "\\1\\2", markdown)
  markdown
}

#' @rdname as.markdown
setMethod(
  "as.markdown", "partition",
  function(
    .Object, meta = getOption("polmineR.meta"), template = get_template(.Object),
    cpos = TRUE, cutoff = NULL, verbose = FALSE,
    ...
  ){
    as.markdown(
      .Object = as(.Object, "subcorpus"),
      meta = meta, template = template, cpos = cpos,
      cutoff = cutoff, verbose = verbose,
      ...
    )
})


#' @rdname as.markdown
setMethod(
  "as.markdown", "subcorpus",
  function(
    .Object,
    meta = getOption("polmineR.meta"), template = get_template(.Object),
    cpos = TRUE, cutoff = NULL, verbose = FALSE,
    ...
  ){
    .message("as.markdown", verbose = verbose)
    # ensure that template requested is available
    if (is.null(template)){
      warning(sprintf("No template available for corpus '%s', using default template.", get_corpus(.Object)))
      template <- default_template
    }
    if (is.null(template[["paragraphs"]])){
      .message("generating paragraphs (no template)", verbose = verbose)
      tokens <- get_token_stream(.Object, p_attribute = "word", cpos = cpos, cutoff = cutoff, ...)
      tokens <- .tagTokens(tokens)
      tokens <- paste(tokens, collapse = " ")
      rawTxt <- paste(tokens, sep = "\n")
      txt <- gsub("(.)\\s([,.:!?])", "\\1\\2", rawTxt)
    } else {
      .message("generating paragraphs (template for paras)", verbose = verbose)
      articles <- apply(
        .Object@cpos, 1,
        function(row) .as.markdown(row, corpus = .Object@corpus, meta = meta, cutoff = cutoff, ...)
        )
      txt <- paste(c("\n", unlist(articles)), collapse = '\n* * *\n')
    }
    txt
    metaInfo <- paste(
      sapply(meta, function(x) sprintf("%s: %s", x, paste(s_attributes(.Object, x), collapse = "|"))),
      collapse = " // "
    )
    corpusInfo <- paste("## Corpus: ", .Object@corpus, "\n\n", sep = "")
    header <- paste(corpusInfo, paste("### ", metaInfo), "\n\n", sep = "")
    txt <- paste(header, txt, '\n', collapse = "\n")
    txt
  })

#' @rdname as.markdown
setMethod("as.markdown", "plpr_partition", function(.Object, meta = NULL, template = get_template(.Object), cpos = FALSE, interjections = TRUE, cutoff = NULL, ...){
  as.markdown(as(.Object, "plpr_subcorpus"), meta = meta, template = template, cpos = cpos, interjections = interjections, cutoff = cutoff, ...)
})


#' @rdname as.markdown
setMethod("as.markdown", "plpr_subcorpus", function(.Object, meta = NULL, template = get_template(.Object), cpos = FALSE, interjections = TRUE, cutoff = NULL, ...){
  # in the function call, meta is actually not needed, required by the calling function
  if (is.null(template)) warning("No template available, formatting fulltext output is likely to fail.")
  if (is.null(meta)) meta <- template[["metadata"]]
  if (interjections){
    strucs_range <- .Object@strucs[length(.Object@strucs)] - .Object@strucs[1] + 1L
    if (strucs_range != length(.Object@strucs)){
      .Object@strucs <- .Object@strucs[1]:.Object@strucs[length(.Object@strucs)]
      # fill regions matrix to include interjections
      .Object@cpos <- RcppCWB::get_region_matrix(
        corpus = .Object@corpus, registry = .Object@registry_dir,
        s_attribute = .Object@s_attribute_strucs, strucs = .Object@strucs
      )
      
    }
  }
  
  # detect where a change of metainformation occurs (somewhat slow)
  metadata <- as.matrix(s_attributes(.Object, s_attribute = meta, unique = FALSE)) 
  if (length(.Object@strucs) > 1L){
    meta_change <- sapply(2L:nrow(metadata), function(i) !all(metadata[i,] == metadata[i - 1L,]))
    meta_change <- c(TRUE, meta_change)
  } else {
    meta_change <- TRUE
  }
  
  type <- cl_struc2str(
    corpus = .Object@corpus, registry = .Object@registry_dir,
    s_attribute = template[["speech"]][["sAttribute"]], struc = .Object@strucs
  )
  
  if (is.numeric(cutoff)){
    beyond_cutoff <- which(cumsum(.Object@cpos[,2] - .Object@cpos[,1]) > cutoff)
    if (length(beyond_cutoff) > 0L){
      threshold <- min(beyond_cutoff)
      if (threshold > 1L){
        metadata <- metadata[1L:threshold,]
        .Object@cpos <- .Object@cpos[1L:threshold,]
      }
    }
  }
  
  markdown <- sapply(
    1L:nrow(metadata),
    function(i) {
      meta <- ""
      if (meta_change[i] == TRUE) { 
        meta <- paste(metadata[i,], collapse=" | ", sep="")
        meta <- paste(
          template[["document"]][["format"]][1],
          meta,
          template[["document"]][["format"]][2],
          collapse = ""
        )
        meta <- as.corpusEnc(meta, corpusEnc = .Object@encoding)
      }
      tokens <- get_token_stream(
        matrix(.Object@cpos[i,], nrow = 1),
        corpus = .Object@corpus, p_attribute = "word", encoding = .Object@encoding,
        cpos = cpos
      )
    tokens <- .tagTokens(tokens)
    plaintext <- paste(tokens, collapse = " ")
    plaintext <- paste(
      template[["speech"]][["format"]][[type[i]]][1],
      plaintext,
      template[["speech"]][["format"]][[type[i]]][1],
      sep = ""
      )
    paste(meta, plaintext)
  })
  markdown <- paste(markdown, collapse = "\n\n")
  markdown <- gsub("(.)\\s([,.:!?])", "\\1\\2", markdown)
  markdown <- gsub("\n - ", "\n", markdown)
  markdown
})
